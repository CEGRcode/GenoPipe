#!/bin/bash
#PBS -l nodes=1:ppn=4
#PBS -l pmem=16gb
#PBS -l walltime=24:00:00
#PBS -A open
#PBS -o logs/depth.did.log.out
#PBS -e logs/depth.did.log.err
#PBS -t 1-3,5-7,9-10

# Each index of the job array t:[1,16] represents a different set of depth simulations. This script will execute DeletionID against all all simulated datasets. Each index corresponds to a different row of depth_simulations.txt which describes the parameters under which each set of simulated data was generated.

# This script will check that 1000 BAM files have been generated before executing DeletionID.

#6hour walltime for yeast 2M depth (t=9,10)
#less time needed for lower read counts
#2hour walltime for yeast 100K depth (t=2,6)

# FIRST CHANGE PATH TO EXECUTE
WRK=/path/to/GenoPipe/paper/SyntheticDeletion
cd $WRK

module load anaconda3
source activate genopipe

INFO=`sed "${PBS_ARRAYID}q;d" depth_simulations.txt`
LOCUS=`awk '{print $1}'  <(echo $INFO)`
DEPTH=`awk '{print $2}'  <(echo $INFO)`

REF=`echo $LOCUS | awk -F'_' '{print $1}'`

OUTPUT=$WRK/results/$LOCUS\_$DEPTH
[ -d $OUTPUT/ID ] || mkdir $OUTPUT/ID

#Check that all BAM files were genertaed first
if [ $(ls $OUTPUT/BAM/*.bam |wc -l ) -lt 1000 ];
then
	NBAM=`ls $OUTPUT/BAM/*.bam |wc -l`
	echo "Insufficient simulations for ${LOCUS}_${DEPTH}. Only have $NBAM BAM files, make sure you generate all 1000 before running DeletionID"
	exit
fi

GENOPIPE=$WRK/../..
cd $GENOPIPE/DeletionID
## Execute Mass DeletionID and record time
echo "**Begin executing DeletionID for ${LOCUS}_${DEPTH}..."
start=`date +%s`
bash identify-Deletion.sh -i $OUTPUT/BAM -o $OUTPUT/ID -d $GENOPIPE/paper/db/$REF\_Del
end=`date +%s`
runtime=$((end-start))
MESSAGE="...mass DeletionID for ${LOCUS} finished in ${runtime}"
echo $MESSAGE
cd $WRK
